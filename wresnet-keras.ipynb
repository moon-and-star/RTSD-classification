{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/transcranial/wide-resnet/blob/master/wide-resnet.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.summary()\n",
    "from util.config import get_config\n",
    "config = get_config('./config.json')\n",
    "\n",
    "# from pprint import pprint\n",
    "# pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=config['train_params']['gpu_num']\n",
      "env: KERAS_BACKEND=tensorflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=config['train_params']['gpu_num']\n",
    "%env KERAS_BACKEND=tensorflow\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import add,merge, Dense, Activation, Flatten, Lambda, Conv2D, AveragePooling2D, BatchNormalization, Dropout\n",
    "from keras.engine import Input, Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import Callback, LearningRateScheduler, ModelCheckpoint, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "import keras.backend as K\n",
    "import json\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zero_pad_channels(x, pad=0):\n",
    "    \"\"\"\n",
    "    Function for Lambda layer\n",
    "    \"\"\"\n",
    "    pattern = [[0, 0], [0, 0], [0, 0], [pad - pad // 2, pad // 2]]\n",
    "    return tf.pad(x, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subsample(x, nb_filters=16, subsample_factor=1):\n",
    "    if subsample_factor > 1:\n",
    "        subsample = (subsample_factor, subsample_factor)\n",
    "    else:\n",
    "        subsample = (1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def subsample_and_shortcut(x, nb_filters=16, subsample_factor=1):\n",
    "    prev_nb_channels = K.int_shape(x)[3]\n",
    "\n",
    "    if subsample_factor > 1:\n",
    "        subsample = (subsample_factor, subsample_factor)\n",
    "        # shortcut: subsample + zero-pad channel dim\n",
    "        shortcut = AveragePooling2D(pool_size=subsample, data_format=\"channels_last\")(x)\n",
    "    else:\n",
    "        subsample = (1, 1)\n",
    "        # shortcut: identity\n",
    "        shortcut = x\n",
    "        \n",
    "    if nb_filters > prev_nb_channels:\n",
    "        shortcut = Lambda(zero_pad_channels,\n",
    "                          arguments={'pad': nb_filters - prev_nb_channels})(shortcut)\n",
    "\n",
    "    return subsample, shortcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def residual_block(x, nb_filters=16, subsample_factor=1):\n",
    "    \n",
    "    subsample, shortcut = subsample_and_shortcut(x, nb_filters, subsample_factor)\n",
    "    \n",
    "    y = BatchNormalization(axis=3)(x)\n",
    "    y = Activation('relu')(y)\n",
    "    y = Conv2D(nb_filters, (3, 3), \n",
    "               kernel_initializer=\"he_normal\", padding=\"same\", data_format=\"channels_last\", strides=subsample)(y)\n",
    "    \n",
    "    y = BatchNormalization(axis=3)(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = Dropout(0.5)(y)\n",
    "    y = Conv2D(nb_filters, (3, 3), \n",
    "        kernel_initializer=\"he_normal\", padding=\"same\", data_format=\"channels_last\", strides=(1,1))(y)\n",
    "    \n",
    "    out = add([y, shortcut])\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_layer(config):\n",
    "    \n",
    "    size = config['img']['img_size'] + 2 * config['img']['padding']\n",
    "    img_rows, img_cols = size, size\n",
    "    \n",
    "    img_channels = 3\n",
    "    inputs = Input(shape=(img_rows, img_cols, img_channels))\n",
    "    print(inputs.shape)\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv1(inputs, config):\n",
    "    x = Conv2D(16, (3, 3), \n",
    "               padding=\"same\", data_format=\"channels_last\", kernel_initializer=\"he_normal\")(inputs)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2(x, config):\n",
    "    blocks_per_group = config['wide_resnet']['metablock_depth']\n",
    "    widening_factor = config['wide_resnet']['width']\n",
    "    \n",
    "    for i in range(0, blocks_per_group):\n",
    "        nb_filters = 16 * widening_factor\n",
    "        x = residual_block(x, nb_filters=nb_filters, subsample_factor=1)\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv3(x, config):\n",
    "    blocks_per_group = config['wide_resnet']['metablock_depth']\n",
    "    widening_factor = config['wide_resnet']['width']\n",
    "    \n",
    "    for i in range(0, blocks_per_group):\n",
    "        nb_filters = 32 * widening_factor\n",
    "        if i == 0:\n",
    "            subsample_factor = 2\n",
    "        else:\n",
    "            subsample_factor = 1\n",
    "        x = residual_block(x, nb_filters=nb_filters, subsample_factor=subsample_factor)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv4(x, config):\n",
    "    blocks_per_group = config['wide_resnet']['metablock_depth']\n",
    "    widening_factor = config['wide_resnet']['width']\n",
    "    \n",
    "    for i in range(0, blocks_per_group):\n",
    "        nb_filters = 64 * widening_factor\n",
    "        if i == 0:\n",
    "            subsample_factor = 2\n",
    "        else:\n",
    "            subsample_factor = 1\n",
    "        x = residual_block(x, nb_filters=nb_filters, subsample_factor=subsample_factor)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.util import  num_of_classes\n",
    "def wresnet(config):\n",
    "    %%time\n",
    "    \n",
    "    inputs = input_layer(config)\n",
    "    x = conv1(inputs, config)\n",
    "    x = conv2(x, config)\n",
    "    x = conv3(x, config)\n",
    "    x = conv4(x, config)\n",
    "   \n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling2D(pool_size=(8, 8), strides=None, padding='valid', data_format=\"channels_last\")(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    predictions = Dense(num_of_classes(config), activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if False:\n",
    "#     batch_size = 64\n",
    "#     nb_epoch = 200\n",
    "#     data_augmentation = False\n",
    "\n",
    "#     # Learning rate schedule\n",
    "#     def lr_sch(epoch):\n",
    "#         if epoch < 60:\n",
    "#             return 0.1\n",
    "#         elif epoch < 120:\n",
    "#             return 0.02\n",
    "#         elif epoch < 160:\n",
    "#             return 0.004\n",
    "#         else:\n",
    "#             return 0.0008\n",
    "\n",
    "#     # Learning rate scheduler callback\n",
    "#     lr_scheduler = LearningRateScheduler(lr_sch)\n",
    "\n",
    "#     # Model saving callback\n",
    "#     #checkpointer = ModelCheckpoint(filepath='stochastic_depth_cifar10.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "#     if not data_augmentation:\n",
    "#         print('Not using data augmentation.')\n",
    "#         history = model.fit(x_train, y_train, \n",
    "#                             batch_size=batch_size, nb_epoch=nb_epoch, verbose=1,\n",
    "#                             validation_data=(x_test, y_test), shuffle=True,\n",
    "#                             callbacks=[lr_scheduler])\n",
    "#     else:\n",
    "#         print('Using real-time data augmentation.')\n",
    "\n",
    "#         # realtime data augmentation\n",
    "#         datagen_train = ImageDataGenerator(\n",
    "#             featurewise_center=False,\n",
    "#             samplewise_center=False,\n",
    "#             featurewise_std_normalization=False,\n",
    "#             samplewise_std_normalization=False,\n",
    "#             zca_whitening=False,\n",
    "#             rotation_range=0,\n",
    "#             width_shift_range=0.125,\n",
    "#             height_shift_range=0.125,\n",
    "#             horizontal_flip=False,\n",
    "#             vertical_flip=False)\n",
    "#         datagen_train.fit(x_train)\n",
    "\n",
    "#         # fit the model on the batches generated by datagen.flow()\n",
    "#         history = model.fit_generator(datagen_train.flow(x_train, y_train, batch_size=batch_size, shuffle=True),\n",
    "#                                       samples_per_epoch=x_train.shape[0], \n",
    "#                                       nb_epoch=nb_epoch, verbose=1,\n",
    "#                                       validation_data=(x_test, y_test),\n",
    "#                                       callbacks=[lr_scheduler])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_generator(config, phase):\n",
    "    if phase == 'train':\n",
    "        return ImageDataGenerator(\n",
    "                    featurewise_center=False,\n",
    "                    samplewise_center=False,\n",
    "                    featurewise_std_normalization=False,\n",
    "                    samplewise_std_normalization=False,\n",
    "                    zca_whitening=False,\n",
    "                    rotation_range=0,\n",
    "    #                 width_shift_range=0.125,\n",
    "    #                 height_shift_range=0.125,\n",
    "                    horizontal_flip=False,\n",
    "                    vertical_flip=False)\n",
    "    else:\n",
    "        return ImageDataGenerator(\n",
    "                    featurewise_center=False,\n",
    "                    samplewise_center=False,\n",
    "                    featurewise_std_normalization=False,\n",
    "                    samplewise_std_normalization=False,\n",
    "                    zca_whitening=False,\n",
    "                    rotation_range=0,\n",
    "    #                 width_shift_range=0.125,\n",
    "    #                 height_shift_range=0.125,\n",
    "                    horizontal_flip=False,\n",
    "                    vertical_flip=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def image_generator(config, phase):\n",
    "     # datagen_train.fit(x_train)\n",
    "    datagen = init_generator(config, phase)\n",
    "    root = config['img']['processed_path']\n",
    "    directory = '{root}/{phase}'.format(**locals())\n",
    "    size = config['img']['img_size'] + 2 * config['img']['padding']\n",
    "    \n",
    "    if phase == 'train':\n",
    "        shuffle = True\n",
    "    else: \n",
    "        shuffle = False\n",
    "    \n",
    "    generator = datagen.flow_from_directory(\n",
    "            directory,  \n",
    "            target_size=(size, size),\n",
    "            batch_size=config['train_params']['batch_size'],\n",
    "            class_mode='categorical',\n",
    "#             seed=42,\n",
    "            save_to_dir=None, \n",
    "            shuffle=shuffle)\n",
    "    \n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_optimizer(config):\n",
    "    lr = config['solver_exact']['base_lr']\n",
    "    opt = SGD(lr=lr, decay=5e-4, momentum=0.9, nesterov=True)\n",
    "    \n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_scheduler(config):\n",
    "    \n",
    "    def lr_sch(epoch):\n",
    "        lr = config['solver_exact']['base_lr']\n",
    "        gamma = lr = config['solver_exact']['gamma']\n",
    "        step = config['train_params']['lr_step']\n",
    "        \n",
    "        return lr * gamma**(epoch//step)\n",
    "    \n",
    "    return LearningRateScheduler(lr_sch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prepare_model(config):\n",
    "    \n",
    "    opt = prepare_optimizer(config)\n",
    "    model = wresnet(config)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.util import dataset_size\n",
    "def train(config):\n",
    "    batch_size = config['train_params']['batch_size']\n",
    "    nb_epoch = config['train_params']['epoch_num']\n",
    "\n",
    "\n",
    "    train_gen = image_generator(config, 'train')\n",
    "    train_size = dataset_size(config, 'train')\n",
    "    \n",
    "    val_gen = image_generator(config, 'val')\n",
    "    val_size = dataset_size(config, 'val')\n",
    "    \n",
    "    \n",
    "    model = prepare_model(config)\n",
    "#     model.summary()\n",
    "    \n",
    "    lr_scheduler = prepare_scheduler(config)\n",
    "    history = model.fit_generator(train_gen,\n",
    "#                                   samples_per_epoch=train_size, \n",
    "                                  steps_per_epoch=train_size / batch_size,\n",
    "                                  epochs=nb_epoch, verbose=1,\n",
    "                                  validation_data=val_gen,\n",
    "                                  validation_steps=val_size / batch_size,\n",
    "                                  callbacks=[lr_scheduler])\n",
    "\n",
    "# for i in range(1):\n",
    "#     x, y = train_generator.__next__()\n",
    "#     imgplot = plt.imshow(x[0, :, :, :].astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
